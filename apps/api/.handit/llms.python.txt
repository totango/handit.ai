# LLM Configuration for Python
{
    "models": {
        "gpt-4": {
            "provider": "openai",
            "model": "gpt-4",
            "temperature": 0.7,
            "max_tokens": 2000
        },
        "gpt-3.5-turbo": {
            "provider": "openai",
            "model": "gpt-3.5-turbo",
            "temperature": 0.7,
            "max_tokens": 2000
        }
    },
    "default_model": "gpt-3.5-turbo"
} 